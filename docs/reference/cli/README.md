<!--

NOTE: THIS DOCUMENT IS GENERATED. DO NOT EDIT THIS FILE MANUALLY.

Instead, use `export_cli_reference.py` to update the generator.

-->

# Command-Line Interface

The [Resoto Shell](/concepts/components/shell.md) CLI supports various commands that allow you to access the graph database.

:::tip

You can pipe commands using `|` and chain multiple commands using `;`.

:::

## Commands

| Command                         | Description                                                                         |
| ------------------------------- | ----------------------------------------------------------------------------------- |
| [`aggregate`](#aggregate)       | Aggregate this query by the provided specification                                  |
| [`ancestors`](#ancestors)       | Select all ancestors of this node in the graph.                                     |
| [`chunk`](#chunk)               | Chunk incoming elements in batches.                                                 |
| [`clean`](#clean)               | Mark all incoming database objects for cleaning.                                    |
| [`count`](#count)               | Count incoming elements or sum defined property.                                    |
| [`descendants`](#descendants)   | Select all descendants of this node in the graph.                                   |
| [`dump`](#dump)                 | Dump all properties of incoming objects.                                            |
| [`echo`](#echo)                 | Send the provided message to downstream                                             |
| [`env`](#env)                   | Retrieve the environment and pass it to the output stream.                          |
| [`flatten`](#flatten)           | Take incoming batches of elements and flattens them to a stream of single elements. |
| [`format`](#format)             | Transform incoming objects as string with a defined format.                         |
| [`head`](#head)                 | Return n first elements of the stream.                                              |
| [`http`](#http)                 | Perform http request with incoming data                                             |
| [`jobs`](#jobs)                 | Manage all jobs.                                                                    |
| [`jq`](#jq)                     | Filter and process json.                                                            |
| [`json`](#json)                 | Parse json and pass parsed objects to the output stream.                            |
| [`kind`](#kind)                 | Retrieves information about the graph data kinds.                                   |
| [`list`](#list)                 | Transform incoming objects as string with defined properties.                       |
| [`predecessors`](#predecessors) | Select all predecessors of this node in the graph.                                  |
| [`protect`](#protect)           | Mark all incoming database objects as protected.                                    |
| [`query`](#query)               | Query the graph.                                                                    |
| [`set_desired`](#set_desired)   | Allows to set arbitrary properties as desired for all incoming database objects.    |
| [`set_metadata`](#set_metadata) | Allows to set arbitrary properties as metadata for all incoming database objects.   |
| [`sleep`](#sleep)               | Suspend execution for an interval of time                                           |
| [`start_task`](#start_task)     | Start a task with the given name.                                                   |
| [`successors`](#successors)     | Select all successor of this node in the graph.                                     |
| [`system`](#system)             | Access and manage system wide properties.                                           |
| [`tag`](#tag)                   | Update a tag with provided value or delete a tag                                    |
| [`tail`](#tail)                 | Return n last elements of the stream.                                               |
| [`templates`](#templates)       | Access the query template library.                                                  |
| [`uniq`](#uniq)                 | Remove all duplicated objects from the stream.                                      |
| [`write`](#write)               | Writes the incoming stream of data to a file in the defined format.                 |

### aggregate

**Aggregate this query by the provided specification**

Usage: aggregate [group_prop, .., group_prop]: [function(), .. , function()]

Part of a query. Using the results of a query by aggregating over properties of this result by aggregating over given properties and applying given aggregation functions.

Parameter: group_prop: the name of the property to use for grouping. Multiple grouping variables are possible. Every grouping variable can be renamed via an as name directive. (prop as prop_name) function(): grouping function to be applied on every resulting node. Following functions are possible: sum, count, min, max, avg The function contains the variable name (e.g.: min(path.to.prop)) It is possible to use static values (e.g.: sum(1)) It is possible to use simple math expressions in the function (e.g. min(path.to.prop \* 3 + 2)) It is possible to name the result of this function (e.g. count(foo) as number_of_foos)

Example: aggregate reported.kind as kind, reported.cloud.name as cloud, reported.region.name as region : sum(1) as count [ { "count": 228, "group": { "cloud": "aws", "kind": "aws_ec2_instance", "region": "us-east-1" }}, { "count": 326, "group": { "cloud": "gcp", "kind": "gcp_instance", "region": "us-west1" }}, . . ] aggregate reported.instance_status as status: sum(reported.cores) as cores, sum(reported.memory) as mem [ { "cores": 116, "mem": 64 , "group": { "status": "busy" }}, { "cores": 2520, "mem": 9824, "group": { "status": "running" }}, { "cores": 257, "mem": 973, "group": { "status": "stopped" }}, { "cores": 361, "mem": 1441, "group": { "status": "terminated" }}, ]

Environment Variables: graph [mandatory]: the name of the graph to operate on

### ancestors

**Select all ancestors of this node in the graph.**

Usage: ancestors [--with-origin] [edge_type]

Part of a query. Select all ancestors of this node in the graph. The graph may contain different types of edges (e.g. the `default` graph or the `delete` graph). In order to define which graph to walk, the edge_type can be specified.

If --with-origin is specified, the current element is included in the result set as well. Assume node A with descendant B with descendant C: A --&gt; B --&gt; C $&gt; query id(C) | ancestors
-&gt; will select B and A
$&gt; query id(C) | predecessor --with-origin -&gt; will select C and B and A

Parameter: --with-origin [Optional, default to false]: includes the current element into the result set. edge_type [Optional, defaults to `delete`]: This argument defines which edge type to use.

Example: metadata prop1 == "a" | ancestors | match prop2 == "b"

Environment Variables: graph [mandatory]: the name of the graph to operate on

### chunk

**Chunk incoming elements in batches.**

Usage: chunk [num]

Take &lt;num&gt; number of elements from the input stream, put them in a list and send a stream of list downstream. The last chunk might have a lower size than the defined chunk size.

Parameter: num [optional, defaults to 100]: the number of elements to put into a chunk.

Example: json [1,2,3,4,5] | chunk 2 # will result in [[1, 2], [3, 4], [5]] json [1,2,3,4,5] | chunk # will result in [[1, 2, 3, 4, 5]]

See: flatten for the reverse operation.

### clean

**Mark all incoming database objects for cleaning.**

Usage: clean [reason]

Mark incoming objects for cleaning. All objects marked as such will be eventually cleaned in the next delete run.

An optional reason can be provided. This reason is used to log each marked element, which can be useful to understand the reason a resource is cleaned later on.

This command assumes, that all incoming elements are either objects coming from a query or are object ids. All objects coming from a query will have a property `id`.

The result of this command will emit the complete object with desired and reported state: { "id": "..", "desired": { .. }, "reported": { .. } }

Parameter: reason [optional]: the reason why this resource is marked for cleaning

Example: query isinstance("ec2") and atime&lt;"-2d" | clean [ { "id": "abc" "desired": { "clean": true }, "reported": { .. } }, . . { "id": "xyz" "desired": { "clean": true }, "reported": { .. } }, ] json [{"id": "id1"}, {"id": "id2"}] | clean [ { "id": "id1", "desired": { "clean": true }, "reported": { .. } }, { "id": "id2", "desired": { "clean": true }, "reported": { .. } }, ] json ["id1", "id2"] | clean [ { "id": "id1", "desired": { "clean": true }, "reported": { .. } }, { "id": "id2", "desired": { "clean": true }, "reported": { .. } }, ]

### count

**Count incoming elements or sum defined property.**

Usage: count [arg]

In case no arg is given: it counts the number of instances provided to count. In case of arg: it pulls the property with the name of arg and counts the occurrences of this property.

Parameter: arg [optional]: Instead of counting the instances, count the occurrences of given instance.

Example: json [{"a": 1}, {"a": 2}, {"a": 3}] | count # will result in [["total matched: 3", "total unmatched: 0"]] json [{"a": 1}, {"a": 2}, {"a": 3}] | count a # will result in [["1:1", "2:1", "3:1", ....]] json [{"a": 1}, {"a": 2}, {"a": 3}] | count b # will result in [["total matched: 0", "total unmatched: 3"]]

### descendants

**Select all descendants of this node in the graph.**

Usage: descendants [--with-origin] [edge_type]

Part of a query. Select all descendants of this node in the graph. The graph may contain different types of edges (e.g. the `default` graph or the `delete` graph). In order to define which graph to walk, the edge_type can be specified.

If --with-origin is specified, the current element is included in the result set as well. Assume node A with descendant B with descendant C: A --&gt; B --&gt; C $&gt; query id(A) | descendants
-&gt; will select B and C
$&gt; query id(A) | descendants --with-origin -&gt; will select A and B and C

Parameter: --with-origin [Optional, default to false]: includes the current element into the result set. edge_type [Optional, defaults to `default`]: This argument defines which edge type to use.

Example: metadata prop1 == "a" | descendants | match prop2 == "b"

Environment Variables: graph [mandatory]: the name of the graph to operate on

### dump

**Dump all properties of incoming objects.**

Usage: dump

Dump all properties of an incoming element. If no output format is given, the output is transformed to fit on one line per element using the list command. Dump will maintain all incoming properties.

See: list, jq, format

### echo

**Send the provided message to downstream**

Usage: echo &lt;message&gt;

Send the provided message to downstream.

Example: echo "test" # will result in ["test"]

### env

**Retrieve the environment and pass it to the output stream.**

Usage: env

Emits the provided environment. This is useful to inspect the environment given to the CLI interpreter.

Example: env # will result in a json object representing the env. E.g.: [{ "env_var1": "test", "env_var2": "foo" }]

### flatten

**Take incoming batches of elements and flattens them to a stream of single elements.**

Usage: flatten

Take array elements from the input stream and put them to the output stream one after the other, while preserving the original order.

Example: json [1, 2, 3, 4, 5] | chunk 2 | flatten # will result in [1, 2, 3, 4, 5] json [1, 2, 3, 4, 5] | flatten # nothing to flat [1, 2, 3, 4, 5] json [[1, 2], 3, [4, 5]] | flatten # will result in [1, 2, 3, 4, 5]

See: chunk which is able to put incoming elements into chunks

### format

**Transform incoming objects as string with a defined format.**

Usage: format [--&lt;format-name&gt;] [format string]

This command creates a string from the json input based on the format string. The format string might contain placeholders in curly braces that access properties of the json object. If a property is not available, it will result in the string `null`.

You can either use a format string or you can use a predefined format. Following predefined formats are available via command line flag:

--json - will create a json string from the incoming json. The result will be a json array. --ndjson - will create a json object for every element, where one element fits on one line. --text - will create a text representation of every element. --cytoscape - will create a string representation in the well known cytoscape format. See: https://js.cytoscape.org/#notation/elements-json --graphml - will create string representaion of the result in graphml format. See:http://graphml.graphdrawing.org --dot - will create a string representation in graphviz dot format. See: https://graphviz.org/doc/info/lang.html

Parameter: format_string [optional]: a string with any content with placeholders to be filled by the object.

Example: json {"a":"b", "b": {"c":"d"}} | format {a}!={b.c} # This will result in [ "b!=d" ] json {"b": {"c":[0,1,2,3]}} | format only select &gt;{b.c[2]}&lt; # This will result in [ "only select &gt;2&lt;" ] json {"b": {"c":[0,1,2,3]}} | format only select &gt;{b.c[2]}&lt; # This will result in [ "only select &gt;2&lt;" ] json {} | format {a}:{b.c.d}:{foo.bla[23].test} # This will result in [ "null:null:null" ] query all | format --json | write out.json # This will write the result to file out.json.

### head

**Return n first elements of the stream.**

Usage: head [num]

Take &lt;num&gt; number of elements from the input stream and send them downstream. The rest of the stream is discarded.

Parameter: num [optional, defaults to 100]: the number of elements to take from the head

Example: json [1,2,3,4,5] | head 2 # will result in [1, 2] json [1,2,3,4,5] | head # will result in [1, 2, 3, 4, 5]

### http

**Perform http request with incoming data**

Usage: http[s] [--compress] [--timeout &lt;seconds&gt;] [--no-ssl-verify] [--no-body] [--nr-of-retries &lt;num&gt;] [http_method] &lt;url&gt; [headers] [query_params]

This command takes every object from the incoming stream and sends this object to the defined http(s) endpoint. The payload of the request contains the object. The shape and format of the object can be adjusted with other commands like: list, format, jq, etc. Note: you can use the chunk command to send chunks of objects. E.g.: query is(volume) limit 30 | chunk 10 | http test.foo.org will perform up to 3 requests, where every request will contain up to 10 elements.

Parameter: --compress [optional]: enable compression of the request body --timeout &lt;seconds&gt; [optional, default: 30]: if the request takes longer than the specified seconds it will be aborted --no-ssl-verify [optional]: the ssl certificate will not be verified. --no-body [optional]: if this flag is enabled, no content is sent in the request body --nr-of-retries [optional, default=3]: in case the request is not successful (no 2xx), the request is retried this often. There will be an exponential backoff between the retries. http_method [optional, default: POST]: one of GET, PUT, POST, DELETE or PATCH url: the full url of the endpoint to call. Example: https://localhost:8080/call/me If the scheme is not defined, it is taken from the command (http or https). If the host is localhost, it can be omitted (e.g. :8080/call/me) headers: a list of http headers can be defined via &lt;header_name&gt;:&lt;header_value&gt; Example: HeaderA:test HeaderB:rest Note: You can use quotes to use whitespace chars: "HeaderC:this is the value" query_params: a list of query parameters can be defined via &lt;param&gt;==&lt;param_value&gt;. Example: param1==test param2==rest Note: You can use quotes to use whitespace chars: "param3==this is the value"

Example: $&gt; query is(volume) and reported.volume_encrypted==false | https my.node.org/handle_unencrypted 3 requests with status 200 sent. $&gt; query is(volume) | chunk 50 | https --compress my.node.org/handle 2 requests with status 200 sent. $&gt; query is(volume) | chunk 50 | https my.node.org/handle "greeting:hello from resotocore" type==volume 2 requests with status 200 sent.

### jobs

**Manage all jobs.**

Usage: jobs [list|show|add|update|delete|activate|deactivate|run|running] [--id &lt;id&gt;] [--schedule &lt;cron_expression&gt;] [--wait-for-event &lt;event_name&gt;] [--timeout &lt;duration_in_seconds&gt;] [command_line] jobs list jobs show &lt;id&gt; jobs add [--id &lt;id&gt;] [--schedule &lt;cron_expression&gt;] [--wait-for-event &lt;event_name&gt;] &lt;command_line&gt; jobs update &lt;id&gt; [--schedule &lt;cron_expression&gt;] [--wait-for-event &lt;event_name&gt; :] &lt;command_line&gt; jobs delete &lt;id&gt; jobs activate &lt;id&gt; jobs deactivate &lt;id&gt; jobs run &lt;id&gt; jobs running

jobs list: get the list of all jobs in the system jobs show &lt;id&gt;: show the current definition of the job defined by given job identifier. jobs add ...: add a job to the task handler with provided identifier, trigger and command line to execute. jobs update &lt;id&gt; ... : update trigger and or command line of an existing job with provided identifier. jobs delete &lt;id&gt;: delete the job with the provided identifier. jobs activate &lt;id&gt;: activate the triggers of a job. jobs deactivate &lt;id&gt;: deactivate the triggers of a job - so the job will not get started. jobs run &lt;id&gt;: run the job as if the trigger would be triggered. jobs running: show all currently running jobs.

A job can be scheduled, react on events or both: - scheduled via defined cron expression - event triggered via defined identifier of event to trigger this job - combined scheduled + event trigger once the schedule triggers this job, it is possible to wait for an incoming event, before the command line is executed.

Note: - if a job is triggered, while it is already running, the invocation will wait for the current run to finish. This means that there will be no parallel execution of jobs with the same identifier at any moment in time. - a command line is not allowed to run longer than the specified timeout. It is killed in case this timeout is exceeded.

Parameter: --id &lt;id&gt; [optional]: The identifier of this job. If no id is defined a random identifier is generated. --schedule &lt;cron_expression&gt; [optional]: defines the recurrent schedule in crontab format. --wait-for-event &lt;event_name&gt; [optional]: if defined, the job waits for the specified event to occur. If this parameter is defined in combination with a schedule, the schedule has to trigger first, before the event will trigger the execution. --timeout [optional, default=3600] Number of seconds, the job is allowed to run. In case this timeout is exceeded, the job run will be killed. command_line [mandatory]: the CLI command line that will be executed, when the job is triggered. Note: It is recommended to wrap the command line into single quotes or escape all CLI terms like pipe or semicolon (| -&gt; \|). Multiple command lines can be defined by separating them via semicolon.

Example: # print hello world every minute to the console $&gt; jobs add --id say-hello --schedule "\* \* \* \* \*" echo hello world Job say-hello added.

    # print all available jobs in the system
    $&gt; jobs list
    id: say-hello
    trigger:
      cron_expression: '* * * * *'
    command: echo hello world

    # show a specific job by identifier
    $&gt; jobs show say-hello
    id: say-hello
    trigger:
      cron_expression: '* * * * *'
    command: echo hello world

    # every morning at 4: wait for message of type collect_done and print a message
    $&gt; jobs add --id early_hi --schedule "0 4 * * *" --wait-for-event collect_done 'match is("volume") | format id'
    Job early_hi added.

    # wait for message of type collect_done and print a message
    $&gt; jobs add --id wait_for_collect_done collect_done: echo hello world
    Job wait_for_collect_done added.

    # run the job directly without waiting for a trigger
    $&gt; jobs run say-hello
    Job say-hello started with id a4bb64cc-7385-11ec-b2cb-dad780437c53.

    # show all currently running jobs
    $&gt; jobs running
    job: say-hello
    started_at: '2022-01-12T09:01:34Z'
    task-id: a4bb64cc-7385-11ec-b2cb-dad780437c53

    # triggers can be activated and deactivated.
    # Deactivated triggers will not trigger the job.
    # The active flag shows the state of activation.
    $&gt; jobs deactivate say-hello
    id: say-hello
    command: echo hello world
    active: false
    trigger:
      cron_expression: '* * * * *'

    # activate the triggers of the job.
    $&gt; jobs activate say-hello
    id: say-hello
    command: echo hello world
    active: true
    trigger:
      cron_expression: '* * * * *'

    # delete a job
    $&gt; jobs delete say-hello
    Job say-hello deleted.

### jq

**Filter and process json.**

Usage: jq &lt;filter&gt;

Use the well known jq JSON processor to manipulate incoming json. Every element from the incoming stream is passed to the this jq command. See: https://stedolan.github.io/jq/ for a list of possible jq arguments.

Parameter: filter: the filter argument for jq.

Example: $&gt; query is(aws_ec2_instance) | jq '.reported.id' ["id-1", "id-2"] Query all aws ec2 instances and then only pick the reported.id. $&gt; query is(aws_ec2_instance) | jq '. | {id: .reported.id, rev:.revision}' [{"id": "id-1", "rev": "1"}, {"id": "id-2", "rev": "5"}]

See also: format, list.

### json

**Parse json and pass parsed objects to the output stream.**

Usage: json &lt;json&gt;

The defined json will be parsed and written to the out stream. If the defined element is a json array, each element will be send downstream.

Example: json "test" # will result in ["test"] json [1,2,3,4] | count # will result in [{ "matched": 4, "not_matched": 0 }]

### kind

**Retrieves information about the graph data kinds.**

Usage: kind [-p property_path] [name_of_kind]

kind gives information about the graph data kinds.

Use case 1: show all available kinds: $&gt; kind This will list all available kinds and print the name as list.

Use case 2: show all details about a specific kind: $&gt; kind graph_root This will show all available information about the given kind.

Use case 3: I want to know the kind of a property in my model $&gt; kind reported.tags.owner Lookup the type of the given property in the model. Assume a complex model A with reported properties: name:string, tags:dictionary[string, string] A lookup of property name reported.tags.owner will yield the type string

Parameter: name_of_kind: the name of the kind to show more detailed information. -p &lt;path&gt;: the path of the property where want to know the kind

Example: kind # will result in the list of kinds e.g. [ cloud, account, region ... ] kind graph_root # will show information about graph root. { "name": "graph_root", .... } kind -p reported.tags # will show the kind of the property with this path.

### list

**Transform incoming objects as string with defined properties.**

Usage: list [props_to_show]

This command creates a string from the json input based on the defined properties to show.

If no prop is defined a predefined list of properties will be shown: - reported.kind as kind - reported.id as id - reported.name as name - reported.age as age - ancestors.cloud.reported.name as cloud - ancestors.account.reported.name as account - ancestors.region.reported.name as region - ancestors.zone.reported.name as zone

If props_to_show is defined, it will override the default and will show the defined properties. The syntax for props_to_show is a comma delimited list of property paths. The property path can be absolute, meaning it includes the section name (reported, desired, metadata). In case the section name is not defined, the reported section is assumed automatically.

The defined property path will be looked for every element in the incoming json. If the value is defined, it will be part of the list line. Undefined values are filtered out and will not be printed.

The property name can be defined via an `as` clause. `reported.kind as kind` would look up the path reported.kind and if the value is defined write kind={value} If no as clause is defined, the name of the last element of property path is taken. In the example above we could write `reported.kind` or `reported.kind as kind` - both would end in the same result. The `as` clause is important, in case the last part of the property path is not sufficient as property name.

Parameter: props_to_show [optional]: a space delimited definition of properties to show

Example: $&gt; query is(aws_ec2_instance) limit 3 | list kind=aws_ec2_instance, id=1, name=sun, ctime=2020-09-10T13:24:45Z, cloud=aws, account=prod, region=us-west-2 kind=aws_ec2_instance, id=2, name=moon, ctime=2021-09-21T01:08:11Z, cloud=aws, account=dev, region=us-west-2 kind=aws_ec2_instance, id=3, name=star, ctime=2021-09-25T23:28:40Z, cloud=aws, account=int, region=us-east-1

    $&gt; query is(aws_ec2_instance) limit 3 | list reported.name
      name=sun
      name=moon
      name=star

    # section name is missing, reported is used automatically
    $&gt; query is(aws_ec2_instance) limit 3 | list kind, name
      kind=aws_ec2_instance, name=sun
      kind=aws_ec2_instance, name=moon
      kind=aws_ec2_instance, name=star

    $&gt; query is(aws_ec2_instance) limit 3 | list kind as a, name as b
      a=aws_ec2_instance, b=sun
      a=aws_ec2_instance, b=moon
      a=aws_ec2_instance, b=star

    $&gt; query is(aws_ec2_instance) limit 3 | list kind as a, name as b, does_not_exist
      a=aws_ec2_instance, b=sun
      a=aws_ec2_instance, b=moon
      a=aws_ec2_instance, b=star

### predecessors

**Select all predecessors of this node in the graph.**

Usage: predecessors [--with-origin] [edge_type]

Part of a query. Select all predecessors of this node in the graph. The graph may contain different types of edges (e.g. the `default` graph or the `delete` graph). In order to define which graph to walk, the edge_type can be specified.

If --with-origin is specified, the current element is included in the result set as well. Assume node A with descendant B: A --&gt; B $&gt; query id(B) | predecessor
-&gt; will select A
$&gt; query id(B) | predecessor --with-origin -&gt; will select A and B

Parameter: --with-origin [Optional, default to false]: includes the current element into the result set. edge_type [Optional, defaults to `default`]: This argument defines which edge type to use.

Example: metadata prop1 == "a" | predecessors | match prop2 == "b"

Environment Variables: graph [mandatory]: the name of the graph to operate on

### protect

**Mark all incoming database objects as protected.**

Usage: protect

Mark incoming objects as protected. All objects marked as such will be safe from deletion.

This command assumes, that all incoming elements are either objects coming from a query or are object ids. All objects coming from a query will have a property `id`.

Example: query isinstance("ec2") and atime&lt;"-2d" | protect [ { "id": "abc" "metadata": { "protected": true }, "reported": { .. } }, . . { "id": "xyz" "metadata": { "protected": true }, "reported": { .. } }, ] json [{"id": "id1"}, {"id": "id2"}] | clean [ { "id": "id1", "metadata": { "protected": true }, "reported": { .. } }, { "id": "id2", "metadata": { "protected": true }, "reported": { .. } }, ] json ["id1", "id2"] | clean [ { "id": "id1", "metadata": { "protected": true }, "reported": { .. } }, { "id": "id2", "metadata": { "protected": true }, "reported": { .. } }, ]

### query

**Query the graph.**

Usage: query [--include-edges] [--explain] &lt;query&gt;

This command allows to query the graph using filters, traversals and functions.

Filters have the form &lt;path.to.property&gt; &lt;op&gt; &lt;value&gt;.

- path is the complete path of names in the json structure combined with a dot (e.g. reported.cpu_count). In case the path contains elements, that are not json conform, they can be put into backticks (e.g. foo.bla.`:-)`.baz).
- operator is one of: &lt;=, &gt;=, &gt;, &lt;, ==, !=, =~, !~, in, not in (e.g. !=)
- value is a json literal (e.g. "test", 23, [1, 2, 3], true, {"a": 12}). Note: the query parser allows to omit the parentheses for strings most of the time. In case the string contains whitespace or a special character, you should put the string into parentheses. Example: reported.cpu_count &gt;= 4, name!="test", title in ["first", "second"]

Filters can be combined with `and` and `or` and use parentheses. Example: (cpu_count&gt;=4 and name!="test") or title in ["first", "second"]

Outbound traversals are traversals from a node in direction of the edge to another node, while inbound traversals walk the graph in opposite direction. Example: Assuming 2 nodes with one connecting directed edge: NodeA ---&gt; NodeB - traversing outbound from NodeA will yield NodeB - traversing inbound from NodeB will yield NodeA The syntax for outbound traversals is --&gt; and for inbound traversals is &lt;--. The traversal also allows to define the number of levels to walk in the graph: -[1:1]-&gt; (shorthand for --&gt;) starts from the current node and selects all nodes that can be reached by walking exactly one step outbound. -[0:1]-&gt; starts (and includes) the current node and selects all nodes that can be reached by walking exactly one step outbound. -[&lt;x&gt;:&lt;y&gt;]-&gt; walks from the current node to all nodes that can be reached with x steps outbound. From here all nodes are selected including all nodes that can be reached in y steps outbound relative to the starting node. -[&lt;x&gt;]-&gt; shorthand -[&lt;x&gt;:&lt;x&gt;]-&gt; -[&lt;x&gt;:]-&gt; walks from the current node to all nodes that can be reached with x steps outbound. From here all nodes to the graph leafs are selected. The same logic is used for inbound traversals (&lt;--, &lt;-[0:1]-, &lt;-[2]-, &lt;-[2:]-).

There are predefined functions that can be used in combination with any filter.

- is(&lt;kind&gt;): selects all nodes that are of type &lt;kind&gt; or any subtype of &lt;kind&gt;. Example: is(volume) will select all GCP disks and all AWS EC2 volumes, since both types inherit from base type volume.
- id(&lt;identifier&gt;): selects the node with the given node identifier &lt;identifier&gt;. Example: id(foo) will select the node with id foo. The id is a synthetic id created by the collector and usually does not have a meaning, other than identifying a node uniquely.
- has_key(&lt;path&gt;): tests if the specified name is defined in the json object. Example: is(volume) and has_key(tags, owner)

Limit and sort. The number of query results can be limited to a defined number by using limit &lt;limit&gt; and sorted by using sort &lt;sort_column&gt; [asc, desc]. Limit and sort is allowed before a traversal and as last statement to the query result. Example: query is(volume) sort volume_size desc limit 3 &lt;-[2]- sort name limit 1

Use --explain to understand the cost of a query. A query explanation has this form (example): { "available_nr_items": 142670, "estimated_cost": 61424, "estimated_nr_items": 1, "full_collection_scan": false, "rating": "Simple" }

- available_nr_items describe the number of all available nodes in the graph.
- estimated_cost shows the absolute cost of this query. See rating for an interpreted number.
- estimated_nr_items estimated number of items returned for this query. It is computed based on query statistics and heuristics and does not reflect the real number.
- full_collection_scan indicates, if a full collection scan is required. In case this is true, the query does not take advantage of any indexes.
- rating The more general rating of this query. Simple: The estimated cost is fine - the query will most probably run smoothly. Complex: The estimated cost is quite high. Check other properties. Maybe an index can be used? Bad: The estimated cost is very high. It will most probably run long and/or will take a lot of resources.

Parameter: --include-edges: This flag indicates, that not only nodes should be returned, but also all related edges. --explain: Instead of executing this query, explain the query cost

Example: # matches documents with reported section like { "reported": { "prop1": "a" ....} } query /reported.prop1 == "a" # resotoshell set's the command section to reported by default. So the query above can simply be written as: query prop1 == "a" # matches documents with desired section like { "desired": { "some": { "nested" : 1 ..}} query /desired.some.nested in [1,2,3] # matches documents with reported section like { "reported": { "array": [1, 2, 3] ... }} # reported.array[*] means any index would suffice, if one element would be 2 query reported.array[*] == 2 # in this example the index is defined explicitly, meaning the second element of the array should be 2 query reported.array[1] == 2 # this will not only select nodes, but also edges. Downstream commands need to handle the different types. query --include-edges is(graph_root) -[0:2]-&gt; # does not execute the query, but will show an explanation of the query cost. query --explain is(graph_root) -[0:2]-&gt;

Environment Variables: graph [mandatory]: the name of the graph to operate on section [optional]: interpret all property paths with respect to this section. With section "reported" set, the query `name=~"test"` would be interpreted as `reported.name=~"test"`. Note: the resotoshell sets the section to reported by default. If you want to quickly override the section on one command line, you can define env vars in from of the command line (e.g.: `section=desired query clean==true`). It is possible to use absolute path using `/`, so the section will not have any effect (e.g.: `query /desired.clean==true`)

See https://docs.some.engineering/manual/discovery.html for a more detailed explanation of query.

### set_desired

**Allows to set arbitrary properties as desired for all incoming database objects.**

Usage: set_desired [property]=[value]

Set one or more desired properties for every database node that is received on the input channel. The desired state of each node in the database is merged with this new desired state, so that existing desired state not defined in this command is not touched.

This command assumes, that all incoming elements are either objects coming from a query or are object ids. All objects coming from a query will have a property `id`.

The result of this command will emit the complete object with desired and reported state: { "id": "..", "desired": { .. }, "reported": { .. } }

Parameter: One or more parameters of form [property]=[value] separated by a space. [property] is the name of the property to set. [value] is a json primitive type: string, int, number, boolean or null. Quotation marks for strings are optional.

Example: query isinstance("ec2") | set_desired a=b b="c" num=2 # will result in [ { "id": "abc" "desired": { "a": "b", "b: "c" "num": 2, "other": "abc" }, "reported": { .. } }, . . { "id": "xyz" "desired": { "a": "b", "b: "c" "num": 2 }, "reported": { .. } }, ] json [{"id": "id1"}, {"id": "id2"}] | set_desired a=b [ { "id": "id1", "desired": { "a": b }, "reported": { .. } }, { "id": "id2", "desired": { "a": b }, "reported": { .. } }, ] json ["id1", "id2"] | set_desired a=b [ { "id": "id1", "desired": { "a": b }, "reported": { .. } }, { "id": "id2", "desired": { "a": b }, "reported": { .. } }, ]

### set_metadata

**Allows to set arbitrary properties as metadata for all incoming database objects.**

Usage: set_metadata [property]=[value]

Set one or more metadata properties for every database node that is received on the input channel. The metadata state of each node in the database is merged with this new metadata state, so that existing metadata state not defined in this command is not touched.

This command assumes, that all incoming elements are either objects coming from a query or are object ids. All objects coming from a query will have a property `id`.

Parameter: One or more parameters of form [property]=[value] separated by a space. [property] is the name of the property to set. [value] is a json primitive type: string, int, number, boolean or null. Quotation marks for strings are optional.

Example: query isinstance("ec2") | set_metadata a=b b="c" num=2 # will result in [ { "id": "abc" "metadata": { "a": "b", "b: "c" "num": 2, "other": "abc" }, "reported": { .. } }, . . { "id": "xyz" "metadata": { "a": "b", "b: "c" "num": 2 }, "reported": { .. } }, ] json [{"id": "id1"}, {"id": "id2"}] | set_metadata a=b [ { "id": "id1", "metadata": { "a": b }, "reported": { .. } }, { "id": "id2", "metadata": { "a": b }, "reported": { .. } }, ] json ["id1", "id2"] | set_metadata a=b [ { "id": "id1", "metadata": { "a": b }, "reported": { .. } }, { "id": "id2", "metadata": { "a": b }, "reported": { .. } }, ]

### sleep

**Suspend execution for an interval of time**

Usage: sleep &lt;seconds&gt;

Sleep the amount of seconds. An empty string is emitted.

Example: sleep 123 # will result in [""] after 123 seconds

### start_task

**Start a task with the given name.**

Usage: start_task &lt;name of task&gt;

Start a task with given task descriptor id.

The configured surpass behaviour of a task definition defines, if multiple tasks of the same task definition are allowed to run in parallel. In case parallel tasks are forbidden a new task can not be started. If a task could be started or not is returned as result message of this command.

Parameter: task_name [mandatory]: The name of the related task definition.

Example: start_task example_task # Will return Task 6d96f5dc has been started

See: add_job, delete_job, jobs

### successors

**Select all successor of this node in the graph.**

Usage: successors [--with-origin] [edge_type]

Part of a query. Select all successors of this node in the graph. The graph may contain different types of edges (e.g. the `default` graph or the `delete` graph). In order to define which graph to walk, the edge_type can be specified.

If --with-origin is specified, the current element is included in the result set as well. Assume node A with descendant B: A --&gt; B $&gt; query id(A) | successor
-&gt; will select B
$&gt; query id(A) | successor --with-origin -&gt; will select A and B

Parameter: --with-origin [Optional, default to false]: includes the current element into the result set. edge_type [Optional, defaults to `default`]: This argument defines which edge type to use.

Example: metadata prop1 == "a" | successors | match prop2 == "b"

Environment Variables: graph [mandatory]: the name of the graph to operate on

### system

**Access and manage system wide properties.**

Usage: system backup create [name] system backup restore &lt;path&gt; system info

system backup create [name]:

Create a system backup for the complete database, which contains:

- backup of all graph data
- backup of all model data
- backup of all persisted jobs/tasks data
- backup of all subscribers data
- backup of all configuration data

This backup can be restored via system backup restore. Since this command creates a complete backup, it can be restored to an empty database.

Note: a backup acquires a global write lock. This basically means, that _no write_ can be performed, while the backup is created! Note: the backup is not encrypted.

Parameter: name [optional] - name of the backup file. If no name is provided the name will be `backup_yyyyMMdd_hmm`. Example: backup_20211022_1028

Example: system backup create # this will create a backup written to backup\_{time_now}. system backup create backup bck_1234 # this will create a backup written to bck_1234.

system backup restore:

Restores the complete database state from a previously generated backup. All existing data in the database will be overwritten. This command will not wipe any existing data: if there are collections in the database, that are not included in the backup, it will not be deleted by this process. In order to restore exactly the same state as in the backup, you should start from an empty database.

Note: a backup acquires a global write lock. This basically means, that _no write_ can be performed, while the backup is restored! Note: After the restore process is done, the resotocore process will stop. It should be restarted by the process supervisor automatically. The restart is necessary to take effect from the changed underlying data source.

path [mandatory] - path to the local backup file.

Example: system backup restore /path/to/backup # this will restore the backup from the given local path.

system info:

Prints information about the currently running system.

Example: system info name: resotocore version: 2.0.0a11 cpus: 8 mem_available: 2.75 GiB mem_total: 16.00 GiB inside_docker: false started_at: '2022-01-20T14:00:17Z'

### tag

**Update a tag with provided value or delete a tag**

Usage: tag update [--nowait] [tag_name new_value] tag delete [--nowait] [tag_name]

This command can be used to update or delete a specific tag. Tags have a name and value - both name and value are strings.

When this command is issued, the change is done on the cloud resource via the cloud specific provider. In case of success, the resulting change is performed in the related cloud. The change in the graph data itself might take up to the next collect run.

The command would wait for th worker to report the result back synchronously. Once the cli command returns, also the tag update/delete is finished. If the command should not wait for the result, the action can be performed in background via the --nowait flag.

There are 2 modes of operations:

- The incoming elements are defined by a query: Example: `match x&gt;2 | tag delete foo` All elements that match the query are updated.
- The incoming elements are defined by a string or string array: Example: `echo id_of_node_23` | tag delete foo` `json ["id1", "id2", "id3"] | tag delete foo` In this case the related strings are interpreted as id and loaded from the graph.

Parameter: command_name [mandatory]: is either update or delete tag_name [mandatory]: the name of the tag to change tag_value: in case of update: the new value of the tag_name --nowait if this flag is defined, the cli will send the tag command to the worker and will not wait for the task to finish.

Example: match x&gt;2 | tag delete foo # will result in [ { "id1": "success" }, { "id2": "success" } .. {} ] echo "id1" | tag delete foo # will result in [ { "id1": "success" } ] json ["id1", "id2"] | tag delete foo # will result in [ { "id1": "success" }, { "id2": "success" } ]

Environment Variables: graph: the name of the graph to operate on.

### tail

**Return n last elements of the stream.**

Usage: tail [num]

Take the last &lt;num&gt; number of elements from the input stream and send them downstream. The beginning of the stream is consumed, but discarded.

Parameter: num [optional, defaults to 100]: the number of elements to return from the end.

Example: json [1,2,3,4,5] | tail 2 # will result in [4, 5] json [1,2,3,4,5] | head # will result in [1, 2, 3, 4, 5]

### templates

**Access the query template library.**

Usage: templates templates &lt;name_of_template&gt; templates add &lt;name_of_template&gt; &lt;query_template&gt; templates update &lt;name_of_template&gt; &lt;query_template&gt; templates delete &lt;name_of_template&gt; templates test key1=value1, key2=value2, ..., keyN=valueN &lt;template_to_expand&gt;

templates: get the list of all templates templates &lt;name&gt;: get the current definition of the template defined by given template name templates add &lt;name&gt; &lt;template&gt;: add a query template to the query template library under given name. templates update &lt;name&gt; &lt;template&gt;: update a query template in the query template library. templates delete &lt;name&gt;: delete the query template with given name. templates test k=v &lt;template_to_expand&gt;: test the defined template.

Placeholders are defined in 2 double curly braces {{placeholder}} and get replaced by the provided placeholder value during render time. The name of the placeholder can be any valid alphanumeric string. The template 'is({{kind}})' with expand parameters kind=volume becomes 'is(volume)' during expand time.

Parameter: name_of_template: The name of the query template. query_template: The query with template placeholders. key=value: any number of key/value pairs separated by comma

Example: $&gt; templates test kind=volume is({{kind}}) is(volume) $&gt; templates add filter_kind is({{kind}}) Template filter_kind added to the query library. is({{kind}}) &gt; templates filter_kind: is({{kind}}) $&gt; templates filter_kind is({{kind}}) $&gt; templates delete filter_kind Template filter_kind deleted from the query library.

### uniq

**Remove all duplicated objects from the stream.**

Usage: uniq

All elements flowing through the uniq command are analyzed and all duplicates get removed. Note: a hash value is computed from json objects, which is ignorant of the order of properties, so that {"a": 1, "b": 2} is declared equal to {"b": 2, "a": 1}

Example: json [1, 2, 3, 1, 2, 3] | uniq # will result in [1, 2, 3] json [{"a": 1, "b": 2}, {"b": 2, "a": 1}] | uniq # will result in [{"a": 1, "b": 2}]

### write

**Writes the incoming stream of data to a file in the defined format.**

Usage: write &lt;file-name&gt;

Writes the result of this command to a file with given name.

Parameter: file-name [mandatory]: The name of the file to write to.

Example: query all limit 3 | format --json | write out.json # Write 3 nodes to the file out.json in json format. query all limit 3 | format --text | write out.txt # Write 3 nodes to the file out.txt in text format.

## Command Aliases

| Alias            | Command      | Description                             |
| ---------------- | ------------ | --------------------------------------- |
| `https`          | `http`       | Perform http request with incoming data |
| `match`          | `query`      | Query the graph.                        |
| `start_workflow` | `start_task` | Start a task with the given name.       |

## Placeholder Strings

| Placeholder   | Example                |
| ------------- | ---------------------- |
| `@DAY@`       | `28`                   |
| `@FRIDAY@`    | `2022-01-28`           |
| `@HOUR@`      | `15`                   |
| `@MINUTE@`    | `43`                   |
| `@MONDAY@`    | `2022-01-31`           |
| `@MONTH@`     | `01`                   |
| `@NOW@`       | `2022-01-28T15:43:34Z` |
| `@SATURDAY@`  | `2022-01-29`           |
| `@SECOND@`    | `34`                   |
| `@SUNDAY@`    | `2022-01-30`           |
| `@THURSDAY@`  | `2022-02-03`           |
| `@TIME@`      | `15:43:34`             |
| `@TODAY@`     | `2022-01-28`           |
| `@TOMORROW@`  | `2022-01-29`           |
| `@TUESDAY@`   | `2022-02-01`           |
| `@TZ@`        | `CET`                  |
| `@TZ_OFFSET@` | `+0100`                |
| `@UTC@`       | `2022-01-28T14:43:34Z` |
| `@WEDNESDAY@` | `2022-02-02`           |
| `@YEAR@`      | `2022`                 |
| `@YESTERDAY@` | `2022-01-27`           |
