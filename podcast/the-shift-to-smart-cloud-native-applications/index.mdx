---
date: 2022-04-26
authors:
  - lars
  - name: Tobi Knaup
    title: Founder & CEO at D2iQ
    image_url: https://avatars.githubusercontent.com/u/53613?v=4
    url: https://linkedin.com/in/tobiasknaup
tags: [Cloud Infrastructure, Kubernetes, Open-Source Software]
image: ./img/banner-social.jpg
description: To build smart cloud-native applications, companies need to build the infrastructure to train their AI models, put them into production, and build differentiated products. It is an entirely new type of workload, with very dynamic and elastic demand for compute and storage.
---

# The Shift to Smart Cloud-Native Applications

[**Tobi Knaup**](https://linkedin.com/in/tobiasknaup) is the CEO and a co-founder at [D2iQ](https://d2iq.com), an enterprise [Kubernetes platform](https://d2iq.com/kubernetes-platform). D2iQ combines the best open-source technology from the cloud-native technology landscape into a single [Kubernetes](https://kubernetes.io) solution. Customers can deploy this solution without worrying about the individual pieces they would otherwise need to assemble, maintain, and update.

In this episode, we discuss the shift to cloud-native infrastructure and how we are now seeing a new class of smart cloud-native applications emerge. Smart cloud-native applications include artificial intelligence (AI) components that leverage data from production applications. These new applications enable entirely new use cases in every industry. Examples are autonomous driving in automotive, medical imaging in healthcare, and fraud detection in banking or crypto trading.

To build smart cloud-native applications, companies need to build the infrastructure to train their AI models, put them into production, and build differentiated products. **It is an entirely new type of workload, with very dynamic and elastic demand for compute and storage.**

It turns out that Kubernetes, with its scheduling and orchestration capabilities, is a perfect fit to support workloads from smart cloud-native applications. Training models requires spinning up large amounts of compute to process data and then scaling back down. By putting model predictions into production, companies can lean on existing code pipeline workflows and monitoring.

This also means that instead of running two separate types of infrastructure, companies can consolidate and run their smart cloud-native applications on the same platforms as their production applications, which generate the data in the first place. The outcome for companies is highly differentiated digital products.

Listen to this episode to learn about Kubernetes, cloud-native architecture, and changes in organization and workflows that technology leaders need to adapt to deliver smart cloud-native applications.

<YoutubeEmbed id="NyfXSMq3qyw" title={metadata.title} date={metadata.date} description={metadata.description} />
